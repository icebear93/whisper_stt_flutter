{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O43TXB0qmpdQ"
      },
      "outputs": [],
      "source": [
        "# !pip install openai, moviepy, pytube, pydub, ffmpeg-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBvsy9QFmpdR"
      },
      "source": [
        "## YouTube 에서 다운로드 후 음성 추출\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvQWX4PPmpdS"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube\n",
        "import os\n",
        "\n",
        "# 유튜브 링크\n",
        "link = \"https://youtu.be/LQS3y7Tckhc?si=pEJdAfSq3On_Uvou\"\n",
        "\n",
        "yt = YouTube(link)\n",
        "filename = yt.streams.filter(only_audio=True).first().download()\n",
        "renamed_file = filename.replace(\".mp4\", \".mp3\")\n",
        "os.rename(filename, renamed_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tspfmjhmpdT"
      },
      "outputs": [],
      "source": [
        "# 다운로드 받은 유튜브 음성 파일을 mp3 파일로 변환\n",
        "# !ffmpeg -i \"[GPTs로 꿀빨기] PPT 제작 자동화.mp3\" -vn -ar 44100 -ac 2 -b:a 192k youtube_audio.wav -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-Z8PZYnmpdT"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "Audio(\"youtube_audio.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO0EIxfompdT"
      },
      "source": [
        "## 로컬 비디오 파일을 오디오 파일로 변환하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcCpBxe2mpdT"
      },
      "outputs": [],
      "source": [
        "import moviepy.editor\n",
        "\n",
        "# 로컬 파일에서 음성 추출\n",
        "original_file = \"Wispher로-자막작업하기_exported.mp4\"\n",
        "renamed_file = original_file[:-4] + \".mp3\"\n",
        "video = moviepy.editor.VideoFileClip(original_file)\n",
        "video.audio.write_audiofile(renamed_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTH7FvXHmpdU"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "Audio(renamed_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te7WnVz6mpdU"
      },
      "source": [
        "## Whisper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 아래는 whisper 토큰 정보를 위한 참고 링크\n",
        "## http://www.teddynote.com/python/chatgpt-python-api/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58ahLbLfmpdU"
      },
      "outputs": [],
      "source": [
        "# 토큰 정보로드를 위한 라이브러리\n",
        "# 설치: pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# 토큰 정보로드\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9y74O8ucmpdU"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yda_9clbmpdU"
      },
      "outputs": [],
      "source": [
        "# 전체 음성파일에 대한 트래스크립트 생성\n",
        "audio_file = open(renamed_file, \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "    file=audio_file,\n",
        "    model=\"whisper-1\",\n",
        "    language=\"ko\",\n",
        "    response_format=\"text\",\n",
        "    temperature=0.0,\n",
        ")\n",
        "\n",
        "print(transcript)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4k-kgQHmpdU"
      },
      "source": [
        "## Wav 파일로 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIMzXDY2mpdU"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# files\n",
        "src = renamed_file\n",
        "dst = renamed_file[:-4] + \".wav\"\n",
        "\n",
        "# convert wav to mp3\n",
        "audSeg = AudioSegment.from_mp3(src)\n",
        "audSeg.export(dst, format=\"wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oQCfFmOmpdV"
      },
      "outputs": [],
      "source": [
        "target_audio = dst\n",
        "target_audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNq0L0lmmpdV"
      },
      "source": [
        "## Audio Segment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J_S5hJGhmpdV"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'target_audio' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msilence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_on_silence, detect_silence\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 오디오 파일 불러오기\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m audio \u001b[38;5;241m=\u001b[39m AudioSegment\u001b[38;5;241m.\u001b[39mfrom_file(\u001b[43mtarget_audio\u001b[49m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m min_silence_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m  \u001b[38;5;66;03m# 무음으로 간주될 최소 길이 (밀리초 단위)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m silence_thresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m30\u001b[39m  \u001b[38;5;66;03m# 무음으로 간주될 데시벨 값\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'target_audio' is not defined"
          ]
        }
      ],
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence, detect_silence\n",
        "\n",
        "# 오디오 파일 불러오기\n",
        "audio = AudioSegment.from_file(target_audio, format=\"wav\")\n",
        "\n",
        "min_silence_len = 350  # 무음으로 간주될 최소 길이 (밀리초 단위)\n",
        "silence_thresh = -35  # 무음으로 간주될 데시벨 값\n",
        "\n",
        "# 무음 부분을 기준으로 오디오 분할\n",
        "chunks = split_on_silence(\n",
        "    audio,\n",
        "    min_silence_len=min_silence_len,  # 무음으로 간주될 최소 길이 (밀리초 단위)\n",
        "    silence_thresh=silence_thresh,  # 무음으로 간주될 데시벨 값\n",
        "    keep_silence=0,\n",
        ")\n",
        "print(len(chunks))\n",
        "\n",
        "silences = detect_silence(\n",
        "    audio, min_silence_len=min_silence_len, silence_thresh=silence_thresh\n",
        ")\n",
        "silences[:10]\n",
        "silences_diff = [s[1] - s[0] for s in silences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKDZtYOxmpdV"
      },
      "outputs": [],
      "source": [
        "output = chunks[0]\n",
        "output += audio[silences[0][0] : silences[0][1]]\n",
        "for i in range(1, 11):\n",
        "    output += chunks[i]\n",
        "    output += audio[silences[i][0] : silences[i][1]]\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9hDU5abmpdV"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# 분할된 각 청크를 파일로 저장 (예시)\n",
        "current_duration = 0.0\n",
        "timeline = []\n",
        "transcripts = []\n",
        "\n",
        "for i, chunk in tqdm(enumerate(chunks), total=len(chunks)):\n",
        "    f_name = \"sample/chunk{i}.wav\"\n",
        "    chunk.export(f_name, format=\"wav\")\n",
        "    try:\n",
        "        transcript = client.audio.transcriptions.create(\n",
        "            file=open(f_name, \"rb\"),\n",
        "            model=\"whisper-1\",\n",
        "            language=\"ko\",\n",
        "            response_format=\"text\",\n",
        "            temperature=0.0,\n",
        "        )\n",
        "    except:\n",
        "        transcript = \"\"\n",
        "\n",
        "    start = current_duration\n",
        "    if i < len(silences_diff):\n",
        "        end = current_duration + chunk.duration_seconds * \\\n",
        "            1000 + silences_diff[i]\n",
        "    else:\n",
        "        end = current_duration + chunk.duration_seconds * 1000\n",
        "\n",
        "    print(int(start), int(end))\n",
        "    timeline.append((start, end))\n",
        "    current_duration = end\n",
        "    transcripts.append(transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7I2eVUampdV"
      },
      "outputs": [],
      "source": [
        "def format_time(ms):\n",
        "    \"\"\"밀리초를 SRT 포맷의 시간 문자열로 변환합니다.\"\"\"\n",
        "    seconds, milliseconds = divmod(ms, 1000)\n",
        "    minutes, seconds = divmod(seconds, 60)\n",
        "    hours, minutes = divmod(minutes, 60)\n",
        "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{int(milliseconds):03d}\"\n",
        "\n",
        "\n",
        "def create_srt(chunks, subtitles, filename):\n",
        "    \"\"\"SRT 파일을 생성합니다.\"\"\"\n",
        "    with open(filename, \"w\") as file:\n",
        "        combined = [\n",
        "            (start, end, text) for (start, end), text in zip(timeline, transcripts)\n",
        "        ]\n",
        "        for i, (start, end, text) in enumerate(combined, start=1):\n",
        "            file.write(f\"{i}\\n\")\n",
        "            file.write(f\"{format_time(start)} --> {format_time(end)}\\n\")\n",
        "            file.write(f\"{text}\\n\\n\")\n",
        "\n",
        "\n",
        "# SRT 파일 생성\n",
        "create_srt(timeline, transcripts, \"subtitles.srt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctZHL-ibmpdV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py-test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
